image: python:3.10

include:
  - project: dke/apps/templates/job-templates
    file: job-templates.yml
  - project: cs/gitlabci-templates
    file: /build-image-using-kaniko.yml

stages:
  - unit-test
  - update-dag
  - nexus_synchronization
  - deploy_image
  - convert_and_deployToBB5
  - generate_doc
  - deploy_doc

variables:
  DOC_DIR: "doc"
  DAG_DIR: "$DOC_DIR/source/figures"
  DOC: "generated/html"
  DEV_BRANCH: "develop"
  REPO_PUSH_TOKEN: $OAUTH2_TOKEN
  COMMIT_SHA: $CI_COMMIT_SHA


.deploy_rules:
  rules:
    - if: $CI_COMMIT_TAG != null
      when: on_success
      variables:
        CI_REGISTRY_IMAGE: $CI_REGISTRY_IMAGE
        REGISTRY_IMAGE_TAG: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH == $DEV_BRANCH
      when: on_success
      variables:
        CI_REGISTRY_IMAGE: $CI_REGISTRY_IMAGE
        REGISTRY_IMAGE_TAG: dev

.add_staging_SSL:
  script:
    - CA_BUNDLE=$(python3 -c "import certifi; print(certifi.where())")
    - echo "$BBP_CA_CERT" >> $CA_BUNDLE
    - export SSL_CERT_FILE=$CA_BUNDLE

.git_setup:
  - git remote add gitlab https://ci:$REPO_PUSH_TOKEN@bbpgitlab.epfl.ch/dke/apps/blue_brain_atlas_pipeline
  - git config user.name "$COMMIT_SHA"
  - git config user.email "bbp-ou-dke@groupes.epfl.ch"
  - git checkout $DEV_BRANCH

unit_test:
  stage: unit-test
  extends: .unit-tests
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
  before_script:
    - pip install -i https://bbpteam.epfl.ch/repository/devpi/simple/ .[dev]
    - export PYTHONPATH=.:$PYTHONPATH
  script:
    #- !reference [.add_staging_SSL, script]
    - !reference [.unit-tests, script]
  variables:
    SRC_PROJECT: '$CI_PROJECT_PATH'
    TEST_FOLDER: 'tests'
    NEXUS_STAGING_TOKEN: '$NEXUS_STAGING_TOKEN'
    SERVICE_TOKEN_USERNAME: '$SERVICE_TOKEN_USERNAME'
    SERVICE_TOKEN_PASSWORD: '$SERVICE_TOKEN_PASSWORD'
    KUBERNETES_MEMORY_LIMIT: 8Gi
    KUBERNETES_MEMORY_REQUEST: 8Gi

update_dags:
  stage: update-dag
  rules:
    - changes:
        paths:
          - snakefile
        compare_to: 'refs/heads/develop'
  before_script:
    - apt update
    - apt-get -y install graphviz
    - pip install -i https://bbpteam.epfl.ch/repository/devpi/simple/ .[dev]
    - !reference [.git_setup]
  script:
    - echo "Update DAG"
    - snakemake  --config SERVICE_TOKEN=True TOKEN_USERNAME=$SERVICE_TOKEN_USERNAME TOKEN_PASSWORD=$SERVICE_TOKEN_PASSWORD  --dag  push_atlas_datasets > $DAG_DIR/dag_push_atlas.gv
    - dot -Tsvg $DAG_DIR/dag_push_atlas.gv > $DAG_DIR/dag_push_atlas.svg
    - echo "Update detailed DAG"
    - snakemake  --config SERVICE_TOKEN=True TOKEN_USERNAME=$SERVICE_TOKEN_USERNAME TOKEN_PASSWORD=$SERVICE_TOKEN_PASSWORD  --filegraph  push_atlas_datasets > $DAG_DIR/dag_push_atlas_fg.gv
    - dot -Tsvg $DAG_DIR/dag_push_atlas_fg.gv > $DAG_DIR/dag_push_atlas_fg.svg
    - git add $DAG_DIR/dag_push_atlas*
    - git diff-index --quiet HEAD  ||  git commit -m "Update DAGs"
    - git push -o ci.skip gitlab $DEV_BRANCH


# Update Nexus Resources
nexus-synchronization:
  stage: nexus_synchronization
  rules:
    - !reference [.deploy_rules, rules]
  variables:
    NEXUS_STAGING_TOKEN: '$NEXUS_STAGING_TOKEN'
    NEXUS_IDS_PATH: "nexus_ids.json"
    METADATA_DIR: "metadata"
    FILE_NEXUS_ID_MAP: "file_nexus_map.json"
  before_script:
    - !reference [.git_setup]
  script:
    - pip install "nexusforge==0.8.1"
    - python synch_nexus.py
    - git add $NEXUS_IDS_PATH $METADATA_DIR/$FILE_NEXUS_ID_MAP
    - git diff-index --quiet HEAD  ||  git commit -m "Update $NEXUS_IDS_PATH"
    - git push -o ci.skip gitlab $DEV_BRANCH

# Build image for pipeline
update-pipeline-image:
  stage: deploy_image
  extends: .build-image-using-kaniko
  rules:
    - !reference [.deploy_rules, rules]
  variables:
    BUILD_PATH: $CI_PROJECT_DIR
    KANIKO_EXTRA_ARGS: "--build-arg CI_JOB_TOKEN=$CI_JOB_TOKEN --build-arg BBP_CA_CERT='$BBP_CA_CERT'"
    KUBERNETES_MEMORY_LIMIT: 4Gi
    KUBERNETES_MEMORY_REQUEST: 4Gi
  before_script:
    - export IFS=''

# Generate documentation and stores the artifact under doc/generated/html
generate-documentation:
  stage: generate_doc
  rules:
      - if: $CI_COMMIT_TAG != null  || $CI_COMMIT_BRANCH == "master" || $CI_COMMIT_BRANCH == "develop" || $CI_MERGE_REQUEST_IID || $CI_COMMIT_MESSAGE =~ /DRAFT$/
        when: on_success
  script: sphinx-build -T --keep-going -b html -c ./$DOC_DIR/source -D language=en ./$DOC_DIR/source $DOC_DIR/$DOC
  before_script:
    - pip install -i https://bbpteam.epfl.ch/repository/devpi/simple/ -r requirements_doc.txt
  artifacts:
    paths:
      - $DOC_DIR/$DOC
  variables:
    KUBERNETES_MEMORY_LIMIT: 4Gi
    KUBERNETES_MEMORY_REQUEST: 4Gi

# Executes deployment of project documentation to bbp-dke-staging Openshift
deploy-documentation-in-registry:
  stage: deploy_doc
  extends: .build-image-using-kaniko
  dependencies:
    - generate-documentation
  rules:
      - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "master"'
        when: on_success
        variables:
          CI_REGISTRY_IMAGE: $CI_REGISTRY_IMAGE/sphinx-documentation-prod
      - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "develop"'
        when: on_success
        variables:
          CI_REGISTRY_IMAGE: $CI_REGISTRY_IMAGE/sphinx-documentation-dev
  variables:
    CI_COMMIT_SHORT_SHA: $CI_COMMIT_SHORT_SHA
    REGISTRY_IMAGE_TAG: $CI_COMMIT_SHORT_SHA-$(date +%s)
    BUILD_PATH: $CI_PROJECT_DIR/$DOC_DIR
    KANIKO_EXTRA_ARGS: "--build-arg CI_PROJECT_DIR=$CI_PROJECT_DIR  --build-arg DOC_DIR=$DOC_DIR  --build-arg DOC_PATH=$DOC"

# Convert Docker to Singularity image and deploy in BB5
convert_and_deploy_job:
  stage:
    convert_and_deployToBB5
  rules:
    - !reference [.deploy_rules, rules]
  needs:
    - update-pipeline-image
  when: on_success
  tags:
    - bb5_map
  variables:
    bb5_constraint: nvme
    bb5_cpus_per_task: 2
    bb5_memory: 4G
    bb5_duration: "10:00"
  script:
    - bash convert_singularity_image.sh
